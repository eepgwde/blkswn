{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weaves\n",
    "\n",
    "blkswn data exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import numpy as np\n",
    "import functools\n",
    "import scipy.special as scis\n",
    "from functools import partial\n",
    "from itertools import permutations, combinations, chain\n",
    "import string\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "import re\n",
    "\n",
    "pd.__version__\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "[f for f in glob.glob(\"data\" + \"/*\", recursive=True)] # list files for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with pandas as CSV, check the data frame dimensions, check the column names are the same.\n",
    "df1 = pd.read_csv('data/csv_file.csv', encoding = 'utf8')\n",
    "df2 = pd.read_csv('data/txt_file.txt', encoding = 'utf8')\n",
    "print((df1.shape, df2.shape))\n",
    "set(df1.columns.values).difference(df2.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.append(df2, ignore_index=True) # and row catenate, re-index the appended dataframe\n",
    "df.shape\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file - real JSON - has true and false not \n",
    "flnm = 'data/json_file.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nested JSON\n",
    "df3 = pd.read_json(flnm, encoding=\"utf-8\")\n",
    "print(df3.shape)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a JSON load and normalize, preserves embedded UTF-8\n",
    "with open(flnm, encoding=\"utf-8\") as f:\n",
    "    d0 = json.load(f)\n",
    "print(len(d0), type(d0))\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = json_normalize(d0)\n",
    "print(df3.shape)\n",
    "df3.head(3)\n",
    "set(df.columns.values).difference(set(df3.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# So same column names! Makes it easier.\n",
    "df = df.append(df3, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./bak/blkswn.pkl\")\n",
    "df.to_json(\"./bak/blkswn.json\", orient='records')\n",
    "\n",
    "df1 = None; df2 = None; df3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as a backup\n",
    "xdf = pd.read_pickle(\"./bak/blkswn.pkl\")\n",
    "print(xdf.shape)\n",
    "xdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bad record in the text file: search 'TELL ME'. And a bad platform.\n",
    "Force some strings to be categories. Sentiment appears to be factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['content.body'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = [ x for x in set(df['properties.platform']) if isinstance(x, str)]\n",
    "v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = df.index[df['properties.platform'].isnull()].tolist()\n",
    "df.loc[i0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[i0,'properties.platform'] = v0[0]\n",
    "df.loc[i0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author.properties.friends'] = df['author.properties.friends'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author.properties.verified'] = df['author.properties.verified'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author.properties.status_count'] = df['author.properties.status_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['properties.platform'] = df['properties.platform'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location.country'] = df['location.country'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['properties.sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['properties.sentiment'] = df['properties.sentiment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = pd.DataFrame({'value': np.random.randint(0, 100, 20)})\n",
    "labels = [ \"{0} - {1}\".format(i, i + 9) for i in range(0, 100, 10) ]\n",
    "zdf['group'] = pd.cut(zdf.value, range(0, 105, 10), right=False, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0, 105, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = list(set(df['properties.sentiment'].tolist()))\n",
    "v1.sort()\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = df\n",
    "\n",
    "labels=('ugly', 'bad', 'good')\n",
    "zdf['s'] = pd.cut(zdf['properties.sentiment'], range(-1, 3), right=False, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf[['properties.sentiment', 's']].info()\n",
    "zdf[['properties.sentiment', 's']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Categorical(zdf['s'], categories=[\"ugly\", \"bad\", \"good\"], ordered=True)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf['s1'] = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf[['properties.sentiment', 's', 's1']].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = zdf.drop(['s'], axis=1)\n",
    "zdf.head(8)\n",
    "df = zdf\n",
    "zdf = None\n",
    "df.to_pickle(\"./bak/blkswn1.pkl\")\n",
    "df.to_json(\"./bak/blkswn1.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility transformer - spot tags\n",
    "def trns0(x, fld=None):\n",
    "    return x[fld].count('@')\n",
    "\n",
    "trns1 = partial(trns0, fld='content.body')\n",
    "    \n",
    "df['at.n'] = df.apply(trns1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility transformer - spot tags\n",
    "def trns0(x, fld=None):\n",
    "    return x[fld].count('#')\n",
    "\n",
    "trns1 = partial(trns0, fld='content.body')\n",
    "    \n",
    "df['hash.n'] = df.apply(trns1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility transformer - word count\n",
    "def trns0(x, fld=None):\n",
    "    return len(x[fld].split())\n",
    "\n",
    "trns1 = partial(trns0, fld='content.body')\n",
    "    \n",
    "df['words.n'] = df.apply(trns1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility transformer - emojis\n",
    "\n",
    "emoticons = set(range(int('1f600',16), int('1f650', 16)))\n",
    "\n",
    "def split_count(text):\n",
    "    n0 = 0\n",
    "    for ch in text:\n",
    "        if ord(ch) in emoticons:\n",
    "            n0 += 1\n",
    "    return n0\n",
    "\n",
    "def trns0(x, fld=None):\n",
    "    return split_count(x[fld])\n",
    "\n",
    "trns1 = partial(trns0, fld='content.body')\n",
    "    \n",
    "df['emoji.n'] = df.apply(trns1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def isEnglish(s):\n",
    "    s = emoji_pattern.sub(r'', s) # no emoji\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "def trns0(x, fld=None):\n",
    "    return isEnglish(x[fld])\n",
    "\n",
    "trns1 = partial(trns0, fld='content.body')\n",
    "    \n",
    "df['english.q'] = df.apply(trns1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['english.q'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets\n",
    "y=df['s1'] # outcome\n",
    "X=df.drop(['s1', 'properties.sentiment', 'content.body', 'properties.platform'], axis=1)\n",
    "X=pd.get_dummies(X, columns =  ['location.country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scaler.transform(X_train) # 1 is known\n",
    "X0 = scaler.transform(X_test)  # is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
